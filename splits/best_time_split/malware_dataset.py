import os
import pandas as pd
import logging
import json

from io import StringIO
from tqdm import tqdm
from multiprocessing import Pool
from splits.best_time_split.config import config
from splits.best_time_split.best_split import (
    compute_best_time_split,
    train_test_split_by_date,
)

sha256_key, first_sub_date_key = "sha256", "first_submission_date"


class MalwareDatasetBuilder:
    def __init__(self):
        self.__base_dir = os.path.dirname(os.path.abspath(__file__))

    def print_json_keys(self, data, indent=0):
        """Recursively print the keys of a JSON object."""
        if isinstance(data, dict):
            for key, value in data.items():
                print("  " * indent + str(key))
                self.print_json_keys(value, indent + 1)
        elif isinstance(data, list):
            if data and isinstance(data[0], (dict, list)):
                print("  " * indent + "[list]")
                self.print_json_keys(data[0], indent + 1)
            else:
                print("  " * indent + "[list of primitives]")

    def process_vt_report(self, vt_report: str):
        with open(vt_report, "r") as report:
            vt_report_j = json.load(report)[0]
            if sha256_key in vt_report_j and first_sub_date_key in vt_report_j:
                pass
            elif "data" in vt_report_j:
                vt_report_j = vt_report_j["data"]["attributes"]
            elif "attributes" in vt_report_j:
                vt_report_j = vt_report_j["attributes"]
            else:
                raise ValueError(
                    f"Expected keys '{sha256_key}' and '{first_sub_date_key}' not found in {vt_report}"
                )
            sha256, first_sub_date = (
                vt_report_j[sha256_key],
                vt_report_j[first_sub_date_key],
            )
        return (sha256, first_sub_date)

    def __build_sha_fsd_df(self, malware_dir_path: str) -> pd.DataFrame:
        """
        Open VT reports and get SHA256 and first_submission_date values for each json.
        """
        logging.info(
            f"Building SHA256 and first submission date DataFrame from {malware_dir_path}"
        )
        families = os.listdir(malware_dir_path)
        vt_reports = []
        for family in tqdm(families):
            vt_reports_names = os.listdir(os.path.join(malware_dir_path, family))
            vt_reports.extend(
                [
                    os.path.join(malware_dir_path, family, vt_report)
                    for vt_report in vt_reports_names
                ]
            )
        with Pool() as pool:
            malwares_first_sub_date = pool.map(self.process_vt_report, vt_reports)
        return pd.DataFrame(
            malwares_first_sub_date, columns=[sha256_key, first_sub_date_key]
        )

    def __build_sha_family_df(self, malware_dir_path: str) -> pd.DataFrame:
        """
        Build dataset with malware's id (SHA256) and family
        """
        logging.info(f"Building SHA256 and family DataFrame from {malware_dir_path}")
        families = os.listdir(malware_dir_path)
        datasets = []
        for family in tqdm(families):
            current_samples = os.listdir(os.path.join(malware_dir_path, family))
            family_dataset = pd.DataFrame({"sha256": current_samples, "family": family})
            datasets.append(family_dataset)
        return pd.concat(datasets, ignore_index=True)

    def malware_family_fsd_df(
        self,
        vt_reports_path: str = None,
        malware_dir_path: str = None,
    ) -> pd.DataFrame:
        vt_reports_path = (
            config.vt_reports_path if vt_reports_path is None else vt_reports_path
        )
        malware_dir_path = (
            config.malware_directory_path
            if malware_dir_path is None
            else malware_dir_path
        )
        df = pd.merge(
            left=self.__build_sha_family_df(malware_dir_path),
            right=self.__build_sha_fsd_df(vt_reports_path),
            on="sha256",
        )

        df[first_sub_date_key] = df[first_sub_date_key].apply(
            lambda t: pd.to_datetime(t, unit="s")
        )
        # df.to_csv("./splits/merge_final.csv")
        return df


class MalwareDataset:
    def __init__(self):
        self.df_malware_family_fsd = MalwareDatasetBuilder().malware_family_fsd_df()
        split: pd.Timestamp = compute_best_time_split(self.df_malware_family_fsd)
        self.training_dataset, self.testing_dataset = train_test_split_by_date(
            self.df_malware_family_fsd, split
        )
